{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b7e2b4c",
   "metadata": {},
   "source": [
    "# **CNN** *Pytorch*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b3b9a1",
   "metadata": {},
   "source": [
    "***\n",
    "### *Imports...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import torchvision\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028ffaf1",
   "metadata": {},
   "source": [
    "***\n",
    "### *CNN...*\n",
    "**Convolutional layer**\n",
    "- In-channels: 1 for greyscale, 3 for RGB. \n",
    "- Out-channels: Controls model complexity. Overfitting vs. underfitting. \n",
    "- Kernelsize: Kernelsize 3x3.\n",
    "- Stride: Controls how fast the filter moves across the image. 1 = 1 pixel at a time for more detail. \n",
    "- Padding: Helps control output size. \n",
    "\n",
    "**Pooling layer**\n",
    "- Kernelsize: Looks at 2x2 blocks.\n",
    "- Stride: Moves 2 pixels per step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d72b4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=26): \n",
    "       \n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #1ST CONVOLUTIONAL LAYER\n",
    "        self.conv1 = nn.Conv2d( \n",
    "            in_channels=in_channels,  \n",
    "            out_channels=32, \n",
    "            kernel_size=3, \n",
    "            stride=1,  \n",
    "            padding=1) \n",
    "         \n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        #POOLING LAYER\n",
    "        self.pool = nn.MaxPool2d( \n",
    "            kernel_size=2, \n",
    "            stride=2)\n",
    "        \n",
    "        #2ND CONVOLUTIONAL LAYER\n",
    "        self.conv2 = nn.Conv2d(  \n",
    "            in_channels=32,  \n",
    "            out_channels=64, \n",
    "            kernel_size=3, \n",
    "            stride=1, \n",
    "            padding=1)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        #DROPOUT LAYER (FOR REGULARIZATION)\n",
    "        self.dropout = nn.Dropout(p=0.3) \n",
    "        \n",
    "        #FULLY CONNECTED LAYER\n",
    "        self.fc1 = nn.Linear(  \n",
    "            64 * 7 * 7, \n",
    "            num_classes)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # Apply first convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # Apply second convolution and ReLU activation\n",
    "        x = self.pool(x)           # Apply max pooling\n",
    "\n",
    "        x = x.view(x.size(0),-1)  # Flatten the tensor\n",
    "        x = self.dropout(x)         #Reduce chance of overfitting\n",
    "        x = self.fc1(x)            # Apply fully connected layer\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" #Prefers GPU else CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a69180",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e13cf",
   "metadata": {},
   "source": [
    "***\n",
    "### *Hyperparamethers...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ed423c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784  # 28x28 pixels (not directly used in CNN)\n",
    "num_classes = 26  # Letters A-Z\n",
    "learning_rate = 0.01\n",
    "batch_size = 64 #Number of imahes processed at once \n",
    "num_epochs = 30 #Number of batches to be processed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225b9ddd",
   "metadata": {},
   "source": [
    "***\n",
    "### *Load data...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633c3c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reformatting and resizing images, and saving them in the variable Transform for later use.\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((28,28),antialias=True), \n",
    "\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(\n",
    "        degrees=0,\n",
    "        translate=(0.1,0.1),\n",
    "        scale=(0.9,1.1)\n",
    "    ),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.1307],std=[0.3081]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.EMNIST(root='emnist-letters-train',split='letters', train=True, download=True, transform=transform, target_transform=lambda y: y - 1)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = datasets.EMNIST(root='emnist-letters-test', split='letters', train=False, download=True, transform=transform, target_transform=lambda y: y - 1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83469c",
   "metadata": {},
   "source": [
    "***\n",
    "### *Initialize network with loss and optimizer...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df996c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(in_channels=1, num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada94105",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b612ce55",
   "metadata": {},
   "source": [
    "### Train network and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, train_accuracies = [], []\n",
    "test_losses, test_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n",
    "    print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # TRAINING \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    model.train()\n",
    "    train_correct, train_total, train_loss = 0, 0, 0.0\n",
    "\n",
    "    for batch_index, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(data) # Forward\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        loss.backward() # Backward\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = targets.size(0)\n",
    "        train_loss += loss.item() * batch_size\n",
    "        \n",
    "        _, preds = scores.max(1)\n",
    "        train_correct += (preds == targets).sum().item()\n",
    "        train_total += batch_size\n",
    "    \n",
    "    train_loss /= train_total\n",
    "    train_acc = 100.0 * train_correct / train_total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # EVALUATION \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    model.eval()\n",
    "    test_correct, test_total, test_loss = 0, 0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            scores = model(x)\n",
    "            \n",
    "            loss = criterion(scores, y)\n",
    "            batch_size = y.size(0)\n",
    "            test_loss += loss.item() * batch_size\n",
    "\n",
    "            _, predictions = scores.max(1) \n",
    "            test_correct += (predictions == y).sum().item() \n",
    "            test_total += batch_size\n",
    "\n",
    "    test_loss /= test_total\n",
    "    test_acc = float(test_correct) / float(test_total) * 100.0\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "        \n",
    "    print(\n",
    "        f\"~~~~~ TRAINING: ~~~~~ \\n \"\n",
    "        f\"Training accuracy: {train_acc:.2f}. \\n \"\n",
    "        f\"Training loss: {train_loss:.4f}. \\n \"\n",
    "        f\" \\n \"\n",
    "        f\"~~~~ EVALUATING: ~~~~ \\n \" \n",
    "        f\"Test accuracy: {test_acc:.2f}. \\n \"\n",
    "        f\"Test loss: {test_loss:.4f}. \\n \"\n",
    "        f\" \\n \"\n",
    "        )\n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # SCHEDULER \n",
    "    # ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    scheduler.step()\n",
    "\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, num_epochs+1)\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(epochs, train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(epochs, test_accuracies, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Training vs Test Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs Test Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_confusion(loader, model):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            scores = model(x) \n",
    "\n",
    "            _, preds = scores.max(1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(y.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(12,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02461_A25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
